name: CI

# Required GitHub Secrets:
# - SOPS_AGE_KEY (required): Decrypt encrypted test environment files
# - CODECOV_TOKEN (required): Upload coverage reports to Codecov
# - SNYK_TOKEN (optional): Enable Snyk security scanning
# Verification: ./scripts/verify-github-secrets.sh

on:
  pull_request:
  push:
    branches: [main, develop]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint-and-type-check:
    name: Lint and Type Check
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Run ESLint
        run: npm run lint

      - name: Run type check
        run: npm run typecheck

      - name: Check code formatting
        run: npm run format:check

  unit-tests:
    name: Unit Tests
    needs: [lint-and-type-check]
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      # Required Secret: SOPS_AGE_KEY
      # Purpose: Decrypt .env.test.enc file for test execution
      - name: Setup SOPS
        uses: ./.github/actions/setup-sops
        with:
          sops-age-key: ${{ secrets.SOPS_AGE_KEY }}

      - name: Decrypt test secrets
        run: sops --decrypt .env.test.enc > .env.test

      # Run all unit tests with coverage thresholds enforced
      - name: Run unit tests with coverage
        run: npx vitest run --config vitest.config.unit.ts --reporter=verbose --coverage

      - name: Cleanup decrypted secrets
        if: always()
        run: rm -f .env.test

      - name: Upload coverage
        uses: actions/upload-artifact@v4
        with:
          name: coverage-unit
          path: coverage/
          retention-days: 7

  # Integration, E2E, Chaos, and Performance tests run in parallel after unit tests pass
  integration-tests:
    name: Integration Tests
    needs: [unit-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 15

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: test_db
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      rabbitmq:
        image: rabbitmq:3.12-management-alpine
        env:
          RABBITMQ_DEFAULT_USER: test
          RABBITMQ_DEFAULT_PASS: test
        options: >-
          --health-cmd "rabbitmq-diagnostics -q ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5672:5672
          - 15672:15672

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Setup SOPS
        uses: ./.github/actions/setup-sops
        with:
          sops-age-key: ${{ secrets.SOPS_AGE_KEY }}

      - name: Decrypt test secrets
        run: sops --decrypt .env.test.enc > .env.test

      - name: Wait for services
        uses: ./.github/actions/wait-for-services

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db

      - name: Run integration tests
        run: npm run test:integration
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db
          RABBITMQ_URL: amqp://test:test@localhost:5672
          REDIS_URL: redis://localhost:6379
          ENABLE_DB_METRICS: 'false'

      - name: Upload coverage
        uses: actions/upload-artifact@v4
        with:
          name: coverage-integration
          path: coverage/
          retention-days: 7

      - name: Cleanup decrypted secrets
        if: always()
        run: rm -f .env.test

  e2e-tests:
    name: E2E Tests
    needs: [unit-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Setup SOPS
        uses: ./.github/actions/setup-sops
        with:
          sops-age-key: ${{ secrets.SOPS_AGE_KEY }}

      - name: Decrypt test secrets
        run: sops --decrypt .env.test.enc > .env.test

      - name: Start test environment
        run: docker compose -f docker-compose.test.yml up -d

      - name: Wait for services
        run: |
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T postgres pg_isready -U test -d test_db; do sleep 2; done'
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T rabbitmq rabbitmq-diagnostics -q ping; do sleep 2; done'
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T redis redis-cli ping; do sleep 2; done'

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db

      - name: Run E2E tests
        run: npm run test:e2e
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db
          RABBITMQ_URL: amqp://test:test@localhost:5672
          REDIS_URL: redis://localhost:6379
          API_URL: http://localhost:3000
          ENABLE_DB_METRICS: 'false'

      - name: Upload coverage
        uses: actions/upload-artifact@v4
        with:
          name: coverage-e2e
          path: coverage/
          retention-days: 7

      - name: Collect docker logs on failure
        if: failure()
        run: |
          docker compose -f docker-compose.test.yml logs > docker-logs.txt

      - name: Upload docker logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: docker-logs
          path: docker-logs.txt
          retention-days: 7

      - name: Cleanup decrypted secrets
        if: always()
        run: rm -f .env.test

      - name: Cleanup
        if: always()
        run: docker compose -f docker-compose.test.yml down -v

  chaos-tests:
    name: Chaos Tests
    needs: [unit-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 20

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: test_db
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      rabbitmq:
        image: rabbitmq:3.12-management-alpine
        env:
          RABBITMQ_DEFAULT_USER: test
          RABBITMQ_DEFAULT_PASS: test
        options: >-
          --health-cmd "rabbitmq-diagnostics -q ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5672:5672
          - 15672:15672

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Setup SOPS
        uses: ./.github/actions/setup-sops
        with:
          sops-age-key: ${{ secrets.SOPS_AGE_KEY }}

      - name: Decrypt test secrets
        run: sops --decrypt .env.test.enc > .env.test

      - name: Wait for services
        uses: ./.github/actions/wait-for-services

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db

      - name: Run chaos tests
        run: npm run test:chaos
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db
          RABBITMQ_URL: amqp://test:test@localhost:5672
          ENABLE_DB_METRICS: 'false'
          CI: true

      - name: Cleanup decrypted secrets
        if: always()
        run: rm -f .env.test

  performance-smoke-test:
    name: Performance Smoke Test
    needs: [unit-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Setup SOPS
        uses: ./.github/actions/setup-sops
        with:
          sops-age-key: ${{ secrets.SOPS_AGE_KEY }}

      - name: Decrypt test secrets
        run: sops --decrypt .env.test.enc > .env.test

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Start test environment
        run: docker compose -f docker-compose.test.yml up -d

      - name: Wait for services
        run: |
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T postgres pg_isready -U test -d test_db; do sleep 2; done'
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T rabbitmq rabbitmq-diagnostics -q ping; do sleep 2; done'
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T redis redis-cli ping; do sleep 2; done'

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db

      - name: Start API server
        run: |
          npm run build
          node dist/src/index.js > /tmp/api.log 2>&1 &
          echo $! > /tmp/api.pid
          echo "API server started with PID $(cat /tmp/api.pid)"
          sleep 15
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db
          RABBITMQ_URL: amqp://test:test@localhost:5672
          REDIS_URL: redis://localhost:6379
          PORT: 3000
          NODE_ENV: test

      - name: Wait for API
        run: |
          echo "Waiting for API to be ready..."
          timeout 90 bash -c 'until curl -sf http://localhost:3000/health | grep -q "ok"; do echo "Still waiting... ($(date +%H:%M:%S))"; sleep 3; done' || {
            echo "API failed to start within timeout!"
            echo "=== API Server Logs ==="
            cat /tmp/api.log || echo "No logs found"
            exit 1
          }
          echo "API is ready!"

      - name: Create results directory
        run: mkdir -p perf-results

      - name: Run performance smoke test
        run: k6 run tests/performance/api-smoke.test.js
        env:
          API_URL: http://localhost:3000

      - name: Stop API server
        if: always()
        run: |
          if [ -f /tmp/api.pid ]; then
            kill $(cat /tmp/api.pid) || true
          fi

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-smoke-results
          path: perf-results/
          retention-days: 7

      - name: Cleanup decrypted secrets
        if: always()
        run: rm -f .env.test

      - name: Cleanup
        if: always()
        run: docker compose -f docker-compose.test.yml down -v

  performance-load-tests:
    name: Performance Load Tests
    needs: [unit-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Setup SOPS
        uses: ./.github/actions/setup-sops
        with:
          sops-age-key: ${{ secrets.SOPS_AGE_KEY }}

      - name: Decrypt test secrets
        run: sops --decrypt .env.test.enc > .env.test

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Start test environment
        run: docker compose -f docker-compose.test.yml up -d

      - name: Wait for services
        run: |
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T postgres pg_isready -U test -d test_db; do sleep 2; done'
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T rabbitmq rabbitmq-diagnostics -q ping; do sleep 2; done'
          timeout 120 bash -c 'until docker compose -f docker-compose.test.yml exec -T redis redis-cli ping; do sleep 2; done'

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db

      - name: Start API server
        run: |
          npm run build
          node dist/src/index.js > /tmp/api.log 2>&1 &
          echo $! > /tmp/api.pid
          echo "API server started with PID $(cat /tmp/api.pid)"
          sleep 15
        env:
          DATABASE_URL: postgres://test:test@localhost:5432/test_db
          RABBITMQ_URL: amqp://test:test@localhost:5672
          REDIS_URL: redis://localhost:6379
          PORT: 3000
          NODE_ENV: test

      - name: Wait for API
        run: |
          echo "Waiting for API to be ready..."
          timeout 90 bash -c 'until curl -sf http://localhost:3000/health | grep -q "ok"; do echo "Still waiting... ($(date +%H:%M:%S))"; sleep 3; done' || {
            echo "API failed to start within timeout!"
            echo "=== API Server Logs ==="
            cat /tmp/api.log || echo "No logs found"
            exit 1
          }
          echo "API is ready!"

      - name: Create results directory
        run: mkdir -p perf-results

      - name: Run API load test
        run: k6 run tests/performance/api-load.test.js --out json=perf-results/api-load.json
        env:
          API_URL: http://localhost:3000
        continue-on-error: true

      - name: Run scheduler load test
        run: k6 run tests/performance/scheduler-load.test.js --out json=perf-results/scheduler-load.json
        env:
          API_URL: http://localhost:3000
        continue-on-error: true

      - name: Run worker throughput test
        run: k6 run tests/performance/worker-throughput.test.js --out json=perf-results/worker-throughput.json
        env:
          API_URL: http://localhost:3000
        continue-on-error: true

      - name: Run E2E load test
        run: k6 run tests/performance/e2e-load.test.js --out json=perf-results/e2e-load.json
        env:
          API_URL: http://localhost:3000
        continue-on-error: true

      - name: Stop API server
        if: always()
        run: |
          if [ -f /tmp/api.pid ]; then
            kill $(cat /tmp/api.pid) || true
          fi

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-load-results
          path: perf-results/
          retention-days: 30

      - name: Cleanup decrypted secrets
        if: always()
        run: rm -f .env.test

      - name: Cleanup
        if: always()
        run: docker compose -f docker-compose.test.yml down -v

  coverage-report:
    name: Coverage Report
    needs: [unit-tests, integration-tests, e2e-tests, chaos-tests, performance-smoke-test, performance-load-tests]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-*
          path: coverage-artifacts/

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Merge coverage reports
        run: |
          mkdir -p coverage

          # Merge V8 coverage files from all test types using a simple Node script
          node -e "
          const fs = require('fs');
          const path = require('path');

          // Find all coverage-final.json files recursively
          function findCoverageFiles(dir) {
            const files = [];
            try {
              const entries = fs.readdirSync(dir, { withFileTypes: true });
              for (const entry of entries) {
                const fullPath = path.join(dir, entry.name);
                if (entry.isDirectory()) {
                  files.push(...findCoverageFiles(fullPath));
                } else if (entry.name === 'coverage-final.json') {
                  files.push(fullPath);
                }
              }
            } catch (e) { /* ignore */ }
            return files;
          }

          const merged = {};
          const coverageFiles = findCoverageFiles('coverage-artifacts');

          for (const file of coverageFiles) {
            try {
              const coverage = JSON.parse(fs.readFileSync(file, 'utf8'));
              // Merge coverage data, preferring higher coverage counts
              for (const [filePath, data] of Object.entries(coverage)) {
                if (!merged[filePath]) {
                  merged[filePath] = data;
                } else {
                  // Merge statement, function, and branch counts
                  const existing = merged[filePath];
                  if (data.s) {
                    for (const key of Object.keys(data.s)) {
                      existing.s[key] = Math.max(existing.s[key] || 0, data.s[key] || 0);
                    }
                  }
                  if (data.f) {
                    for (const key of Object.keys(data.f)) {
                      existing.f[key] = Math.max(existing.f[key] || 0, data.f[key] || 0);
                    }
                  }
                  if (data.b) {
                    for (const key of Object.keys(data.b)) {
                      existing.b[key] = existing.b[key].map((v, i) => Math.max(v, data.b[key][i] || 0));
                    }
                  }
                }
              }
            } catch (e) {
              console.error('Error processing', file, e.message);
            }
          }

          fs.writeFileSync('coverage/coverage-final.json', JSON.stringify(merged, null, 2));
          console.log('Merged', Object.keys(merged).length, 'files from', coverageFiles.length, 'reports');

          // Generate coverage-summary.json from Istanbul format data
          let totalStatements = 0, coveredStatements = 0;
          let totalBranches = 0, coveredBranches = 0;
          let totalFunctions = 0, coveredFunctions = 0;

          for (const [filePath, data] of Object.entries(merged)) {
            if (data.s) {
              for (const [key, count] of Object.entries(data.s)) {
                totalStatements++;
                if (count > 0) coveredStatements++;
              }
            }
            if (data.b) {
              for (const [key, counts] of Object.entries(data.b)) {
                for (const count of counts) {
                  totalBranches++;
                  if (count > 0) coveredBranches++;
                }
              }
            }
            if (data.f) {
              for (const [key, count] of Object.entries(data.f)) {
                totalFunctions++;
                if (count > 0) coveredFunctions++;
              }
            }
          }

          const pct = (c, t) => t === 0 ? 100 : Math.round((c / t) * 10000) / 100;
          const summary = {
            total: {
              lines: { total: totalStatements, covered: coveredStatements, skipped: 0, pct: pct(coveredStatements, totalStatements) },
              statements: { total: totalStatements, covered: coveredStatements, skipped: 0, pct: pct(coveredStatements, totalStatements) },
              functions: { total: totalFunctions, covered: coveredFunctions, skipped: 0, pct: pct(coveredFunctions, totalFunctions) },
              branches: { total: totalBranches, covered: coveredBranches, skipped: 0, pct: pct(coveredBranches, totalBranches) }
            }
          };

          fs.writeFileSync('coverage/coverage-summary.json', JSON.stringify(summary, null, 2));
          console.log('Coverage:', summary.total.statements.pct + '% statements,', summary.total.functions.pct + '% functions,', summary.total.branches.pct + '% branches');
          "

      - name: Check coverage threshold
        run: bash scripts/coverage/check-thresholds.sh coverage/coverage-summary.json
        continue-on-error: false

      # Required Secret: CODECOV_TOKEN
      # Purpose: Upload coverage reports to Codecov for tracking and analysis
      # Setup: Get token from https://codecov.io/ and run 'gh secret set CODECOV_TOKEN'
      - name: Upload merged coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage/lcov.info
          flags: unittests,integration,e2e
          name: codecov-umbrella
          fail_ci_if_error: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Update coverage history
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          if [ -f scripts/coverage/update-history.sh ]; then
            bash scripts/coverage/update-history.sh
          fi

      - name: Comment coverage on PR
        if: github.event_name == 'pull_request'
        uses: romeovs/lcov-reporter-action@v0.3.1
        with:
          lcov-file: ./coverage/lcov.info
          github-token: ${{ secrets.GITHUB_TOKEN }}
          delete-old-comments: true

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app
        with:
          install-dependencies: 'false'

      - name: Run npm audit
        run: npm audit --audit-level=moderate
        continue-on-error: true

      # Optional Secret: SNYK_TOKEN
      # Purpose: Enable Snyk vulnerability scanning for dependencies
      # Setup: Get token from https://snyk.io/ and run 'gh secret set SNYK_TOKEN'
      # Note: Workflow continues if token is missing (graceful degradation)
      - name: Run Snyk security scan
        uses: snyk/actions/node@master
        continue-on-error: true
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high

  build:
    name: Build
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js and dependencies
        uses: ./.github/actions/setup-node-app

      - name: Build application
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
          retention-days: 7

  all-checks-passed:
    name: All Checks Passed
    needs:
      - lint-and-type-check
      - unit-tests
      - unit-tests
      - integration-tests
      - e2e-tests
      - chaos-tests
      - performance-smoke-test
      - performance-load-tests
      - coverage-report
      - security-scan
      - build
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Check all jobs
        run: |
          if [[ "${{ needs.lint-and-type-check.result }}" != "success" ||
                "${{ needs.unit-tests.result }}" != "success" ||
                "${{ needs.unit-tests.result }}" != "success" ||
                "${{ needs.integration-tests.result }}" != "success" ||
                "${{ needs.e2e-tests.result }}" != "success" ||
                "${{ needs.chaos-tests.result }}" != "success" ||
                "${{ needs.performance-smoke-test.result }}" != "success" ||
                "${{ needs.performance-load-tests.result }}" != "success" ||
                "${{ needs.coverage-report.result }}" != "success" ||
                "${{ needs.build.result }}" != "success" ]]; then
            echo "One or more required checks failed"
            exit 1
          fi
          echo "All required checks passed!"
